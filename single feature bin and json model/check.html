<!DOCTYPE html>
<html>
<head>
    <title>TFJS Model Prediction</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"></script>
    <style>
        body { font-family: Arial, sans-serif; max-width: 600px; margin: 0 auto; padding: 20px; }
        #result { margin-top: 20px; padding: 10px; border: 1px solid #ddd; min-height: 50px; }
        input, button { padding: 8px; margin: 5px 0; }
        button { cursor: pointer; }
    </style>
</head>
<body>
    <h1>Model Prediction</h1>
    <div>
        <label for="inputValue">Input Value:</label>
        <input type="number" id="inputValue" value="10" step="0.1">
        <button onclick="predict()">Predict</button>
    </div>
    <div id="result">Loading model...</div>

    <script>
        let model;
        
        // 1️⃣ Update this path based on where your model.json is hosted
        const modelPath = 'model.json';  // If hosted locally or in the same directory
        // If you host it on Google Drive or a public URL, use the full path:
        // const modelPath = 'https://your_hosted_model_link/tfjs_model/model.json';

        // 2️⃣ Load the TensorFlow.js model
        async function loadModel() {
            try {
                model = await tf.loadGraphModel(modelPath);
                console.log("Model loaded. Input shape:", model.inputs[0].shape);
                document.getElementById('result').innerHTML = "Model ready!";
            } catch (err) {
                console.error("Load error:", err);
                document.getElementById('result').innerHTML = 
                    `Error: ${err.message}<br>Check console and file paths.`;
            }
        }

        // 3️⃣ Function to make predictions
        async function predict() {
            if (!model) {
                alert("Model not loaded yet");
                return;
            }

            try {
                const inputValue = parseFloat(document.getElementById('inputValue').value);
                const inputTensor = tf.tensor2d([[inputValue]], [1, 1]);
                const outputTensor = model.predict(inputTensor);
                const prediction = await outputTensor.data();

                inputTensor.dispose();
                outputTensor.dispose();

                document.getElementById('result').innerHTML = 
                    `Prediction: ${prediction[0].toFixed(2)}`;
            } catch (err) {
                console.error("Prediction error:", err);
                document.getElementById('result').innerHTML = 
                    `Prediction failed: ${err.message}`;
            }
        }

        // 4️⃣ Initialize model loading
        loadModel();
    </script>
</body>
</html>
